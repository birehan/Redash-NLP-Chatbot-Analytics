{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahLXbzwUfudc"
      },
      "source": [
        "##### This is just a sample code so that you can understand how to use function calling it not a starter code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "os69S_Hpfudg",
        "outputId": "f55cf355-b544-45b3-acf9-66ad0948b225",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.6.1 typing-extensions-4.9.0\n"
          ]
        }
      ],
      "source": [
        "# import openai\n",
        "# import os\n",
        "# import json\n",
        "# import requests\n",
        "# from pprint import pprint\n",
        "# import json\n",
        "# import openai\n",
        "# import requests\n",
        "# from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "# from termcolor import colored\n",
        "\n",
        "# GPT_MODEL = \"gpt-3.5-turbo-0613\"\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3B8QYdRfudl"
      },
      "source": [
        "##### In the example below LLM acts as an intermediary that translates a user's natural language request into a structured SQL query, which is then executed by a database tool to fetch and return the relevant data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aC7Su9Eqfudm"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "from openai import OpenAI\n",
        "_ = load_dotenv(find_dotenv())\n",
        "openai.api_key  = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fss33aetfudn",
        "outputId": "544f47b7-dbc6-4f71-a471-4563e094a3c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Opened database successfully\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect(\"data/chinook.db\")\n",
        "print(\"Opened database successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fk2zhUPFfudp"
      },
      "outputs": [],
      "source": [
        "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
        "def chat_completion_request(messages, tools=None, tool_choice=None, model=GPT_MODEL):\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
        "    }\n",
        "    json_data = {\"model\": model, \"messages\": messages}\n",
        "    if tools is not None:\n",
        "        json_data.update({\"tools\": tools})\n",
        "    if tool_choice is not None:\n",
        "        json_data.update({\"tool_choice\": tool_choice})\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            \"https://api.openai.com/v1/chat/completions\",\n",
        "            headers=headers,\n",
        "            json=json_data,\n",
        "        )\n",
        "\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(\"Unable to generate ChatCompletion response\")\n",
        "        print(f\"Exception: {e}\")\n",
        "        return e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ESx7Zrgfudr"
      },
      "outputs": [],
      "source": [
        "def pretty_print_conversation(messages):\n",
        "    role_to_color = {\n",
        "        \"system\": \"red\",\n",
        "        \"user\": \"green\",\n",
        "        \"assistant\": \"blue\",\n",
        "        \"tool\": \"magenta\",\n",
        "    }\n",
        "\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"system\":\n",
        "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"user\":\n",
        "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
        "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
        "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"tool\":\n",
        "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pts2wlutfudt"
      },
      "outputs": [],
      "source": [
        "def get_table_names(conn):\n",
        "    \"\"\"Return a list of table names.\"\"\"\n",
        "    table_names = []\n",
        "    tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "    for table in tables.fetchall():\n",
        "        table_names.append(table[0])\n",
        "    return table_names\n",
        "\n",
        "\n",
        "def get_column_names(conn, table_name):\n",
        "    \"\"\"Return a list of column names.\"\"\"\n",
        "    column_names = []\n",
        "    columns = conn.execute(f\"PRAGMA table_info('{table_name}');\").fetchall()\n",
        "    for col in columns:\n",
        "        column_names.append(col[1])\n",
        "    return column_names\n",
        "\n",
        "\n",
        "def get_database_info(conn):\n",
        "    \"\"\"Return a list of dicts containing the table name and columns for each table in the database.\"\"\"\n",
        "    table_dicts = []\n",
        "    for table_name in get_table_names(conn):\n",
        "        columns_names = get_column_names(conn, table_name)\n",
        "        table_dicts.append({\"table_name\": table_name, \"column_names\": columns_names})\n",
        "    return table_dicts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xr8h1fvTfudu"
      },
      "outputs": [],
      "source": [
        "database_schema_dict = get_database_info(conn)\n",
        "database_schema_string = \"\\n\".join(\n",
        "    [\n",
        "        f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
        "        for table in database_schema_dict\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Af9ynbKfudv"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"ask_database\",\n",
        "            \"description\": \"Use this function to answer user questions about music. Input should be a fully formed SQL query.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"query\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": f\"\"\"\n",
        "                                SQL query extracting info to answer the user's question.\n",
        "                                SQL should be written using this database schema:\n",
        "                                {database_schema_string}\n",
        "                                The query should be returned in plain text, not in JSON.\n",
        "                                \"\"\",\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"query\"],\n",
        "            },\n",
        "        }\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8PIGccBfudv"
      },
      "outputs": [],
      "source": [
        "def ask_database(conn, query):\n",
        "    \"\"\"Function to query SQLite database with a provided SQL query.\"\"\"\n",
        "    try:\n",
        "        results = str(conn.execute(query).fetchall())\n",
        "    except Exception as e:\n",
        "        results = f\"query failed with error: {e}\"\n",
        "    return results\n",
        "\n",
        "def execute_function_call(message):\n",
        "    if message[\"tool_calls\"][0][\"function\"][\"name\"] == \"ask_database\":\n",
        "        query = json.loads(message[\"tool_calls\"][0][\"function\"][\"arguments\"])[\"query\"]\n",
        "        results = ask_database(conn, query)\n",
        "    else:\n",
        "        results = f\"Error: function {message['tool_calls'][0]['function']['name']} does not exist\"\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHAJ4Fshfudw",
        "outputId": "edbc29ed-74b9-491c-c5a3-62fb06d757c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Response [200]>\n",
            "=================== {'id': 'chatcmpl-8cs9X4pQlX27keMSR8wZyw6xiRhJJ', 'object': 'chat.completion', 'created': 1704275319, 'model': 'gpt-3.5-turbo-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'call_JbbiG77hRIvCqH1MDb1Mj5oo', 'type': 'function', 'function': {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT artists.Name, COUNT(tracks.TrackId) AS track_count FROM artists JOIN albums ON artists.ArtistId = albums.ArtistId JOIN tracks ON albums.AlbumId = tracks.AlbumId GROUP BY artists.ArtistId ORDER BY track_count DESC LIMIT 5\"\\n}'}}]}, 'logprobs': None, 'finish_reason': 'tool_calls'}], 'usage': {'prompt_tokens': 407, 'completion_tokens': 67, 'total_tokens': 474}, 'system_fingerprint': None}\n",
            "=================== {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT artists.Name, COUNT(tracks.TrackId) AS track_count FROM artists JOIN albums ON artists.ArtistId = albums.ArtistId JOIN tracks ON albums.AlbumId = tracks.AlbumId GROUP BY artists.ArtistId ORDER BY track_count DESC LIMIT 5\"\\n}'}\n",
            "\u001b[31msystem: Answer user questions by generating SQL queries against the Chinook Music Database.\n",
            "\u001b[0m\n",
            "\u001b[32muser: Hi, who are the top 5 artists by number of tracks?\n",
            "\u001b[0m\n",
            "\u001b[34massistant: {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT artists.Name, COUNT(tracks.TrackId) AS track_count FROM artists JOIN albums ON artists.ArtistId = albums.ArtistId JOIN tracks ON albums.AlbumId = tracks.AlbumId GROUP BY artists.ArtistId ORDER BY track_count DESC LIMIT 5\"\\n}'}\n",
            "\u001b[0m\n",
            "\u001b[35mfunction (ask_database): [('Iron Maiden', 213), ('U2', 135), ('Led Zeppelin', 114), ('Metallica', 112), ('Deep Purple', 92)]\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "messages = []\n",
        "messages.append({\"role\": \"system\", \"content\": \"Answer user questions by generating SQL queries against the Chinook Music Database.\"})\n",
        "messages.append({\"role\": \"user\", \"content\": \"Hi, who are the top 5 artists by number of tracks?\"})\n",
        "chat_response = chat_completion_request(messages, tools)\n",
        "print(\"===================\",chat_response.json())\n",
        "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
        "assistant_message['content'] = str(assistant_message[\"tool_calls\"][0][\"function\"])\n",
        "print(\"===================\",assistant_message['content'])\n",
        "messages.append(assistant_message)\n",
        "if assistant_message.get(\"tool_calls\"):\n",
        "    results = execute_function_call(assistant_message)\n",
        "    messages.append({\"role\": \"tool\", \"tool_call_id\": assistant_message[\"tool_calls\"][0]['id'], \"name\": assistant_message[\"tool_calls\"][0][\"function\"][\"name\"], \"content\": results})\n",
        "pretty_print_conversation(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiNFO6lSfudx",
        "outputId": "81936a96-b255-437e-dd7f-fd315b506952"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Response [200]>\n",
            "\u001b[31msystem: Answer user questions by generating SQL queries against the Chinook Music Database.\n",
            "\u001b[0m\n",
            "\u001b[32muser: Hi, who are the top 5 artists by number of tracks?\n",
            "\u001b[0m\n",
            "\u001b[34massistant: {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT artists.Name, COUNT(tracks.TrackId) AS TrackCount FROM artists JOIN albums ON artists.ArtistId = albums.ArtistId JOIN tracks ON albums.AlbumId = tracks.AlbumId GROUP BY artists.ArtistId ORDER BY TrackCount DESC LIMIT 5;\"\\n}'}\n",
            "\u001b[0m\n",
            "\u001b[35mfunction (ask_database): [('Iron Maiden', 213), ('U2', 135), ('Led Zeppelin', 114), ('Metallica', 112), ('Deep Purple', 92)]\n",
            "\u001b[0m\n",
            "\u001b[32muser: What is the name of the album with the most tracks?\n",
            "\u001b[0m\n",
            "\u001b[34massistant: {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT albums.Title, COUNT(tracks.TrackId) AS TrackCount FROM albums JOIN tracks ON albums.AlbumId = tracks.AlbumId GROUP BY albums.AlbumId ORDER BY TrackCount DESC LIMIT 1;\"\\n}'}\n",
            "\u001b[0m\n",
            "\u001b[35mfunction (ask_database): [('Greatest Hits', 57)]\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "messages.append({\"role\": \"user\", \"content\": \"What is the name of the album with the most tracks?\"})\n",
        "chat_response = chat_completion_request(messages, tools)\n",
        "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
        "assistant_message['content'] = str(assistant_message[\"tool_calls\"][0][\"function\"])\n",
        "messages.append(assistant_message)\n",
        "if assistant_message.get(\"tool_calls\"):\n",
        "    results = execute_function_call(assistant_message)\n",
        "    messages.append({\"role\": \"tool\", \"tool_call_id\": assistant_message[\"tool_calls\"][0]['id'], \"name\": assistant_message[\"tool_calls\"][0][\"function\"][\"name\"], \"content\": results})\n",
        "pretty_print_conversation(messages)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5PUOQBEfudx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tutorial",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}