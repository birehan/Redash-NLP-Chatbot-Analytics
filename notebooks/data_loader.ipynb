{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': 'postgres', 'password': '', 'database': 'youtube_database', 'host': '172.17.0.1', 'port': '15432'}\n"
     ]
    }
   ],
   "source": [
    "from utils import run_sql_query, populate_dataframe_to_database, create_table_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:22:24,384:logger:Log success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:22:24,727:logger:Inserted 5116 rows into the database table device_type_chart_data.\n",
      "2024-01-04 20:22:24,737:logger:Log success\n",
      "2024-01-04 20:22:24,847:logger:Inserted 5 rows into the database table device_type_table_data.\n",
      "2024-01-04 20:22:24,868:logger:Log success\n",
      "2024-01-04 20:22:25,134:logger:Inserted 10232 rows into the database table subscription_source_chart_data.\n",
      "2024-01-04 20:22:25,147:logger:Log success\n",
      "2024-01-04 20:22:25,268:logger:Inserted 9 rows into the database table subscription_source_table_data.\n",
      "2024-01-04 20:22:25,296:logger:Log success\n",
      "2024-01-04 20:22:25,448:logger:Inserted 502 rows into the database table viewership_by_date_table_data.\n",
      "2024-01-04 20:22:25,471:logger:Log success\n",
      "2024-01-04 20:22:25,596:logger:Inserted 2 rows into the database table viewer_gender_table_data.\n",
      "2024-01-04 20:22:25,617:logger:Log success\n",
      "2024-01-04 20:22:26,103:logger:Inserted 11511 rows into the database table traffic_source_chart_data.\n",
      "2024-01-04 20:22:26,132:logger:Log success\n",
      "2024-01-04 20:22:26,269:logger:Inserted 11 rows into the database table traffic_source_table_data.\n",
      "2024-01-04 20:22:26,299:logger:Log success\n",
      "2024-01-04 20:22:26,584:logger:Inserted 10232 rows into the database table subtitles_and_cc_chart_data.\n",
      "2024-01-04 20:22:26,598:logger:Log success\n",
      "2024-01-04 20:22:26,697:logger:Inserted 9 rows into the database table subtitles_and_cc_table_data.\n",
      "2024-01-04 20:22:26,716:logger:Log success\n",
      "2024-01-04 20:22:26,870:logger:Inserted 3837 rows into the database table new_and_returning_viewers_chart_data.\n",
      "2024-01-04 20:22:26,886:logger:Log success\n",
      "2024-01-04 20:22:26,990:logger:Inserted 4 rows into the database table new_and_returning_viewers_table_data.\n",
      "2024-01-04 20:22:27,022:logger:Log success\n",
      "2024-01-04 20:22:27,628:logger:Inserted 20464 rows into the database table operating_system_chart_data.\n",
      "2024-01-04 20:22:27,642:logger:Log success\n",
      "2024-01-04 20:22:27,752:logger:Inserted 17 rows into the database table operating_system_table_data.\n",
      "2024-01-04 20:22:27,780:logger:Log success\n",
      "2024-01-04 20:22:28,020:logger:Inserted 6395 rows into the database table cities_chart_data.\n",
      "2024-01-04 20:22:28,038:logger:Log success\n",
      "2024-01-04 20:22:28,267:logger:Inserted 9 rows into the database table cities_table_data.\n",
      "2024-01-04 20:22:28,292:logger:Log success\n",
      "2024-01-04 20:22:28,453:logger:Inserted 4 rows into the database table viewer_age_table_data.\n",
      "2024-01-04 20:22:28,493:logger:Log success\n",
      "2024-01-04 20:22:28,680:logger:Inserted 2558 rows into the database table subscription_status_chart_data.\n",
      "2024-01-04 20:22:28,695:logger:Log success\n",
      "2024-01-04 20:22:28,800:logger:Inserted 3 rows into the database table subscription_status_table_data.\n",
      "2024-01-04 20:22:28,833:logger:Log success\n",
      "2024-01-04 20:22:29,706:logger:Inserted 37091 rows into the database table geography_chart_data.\n",
      "2024-01-04 20:22:29,722:logger:Log success\n",
      "2024-01-04 20:22:29,832:logger:Inserted 30 rows into the database table geography_table_data.\n",
      "2024-01-04 20:22:29,856:logger:Log success\n",
      "2024-01-04 20:22:30,164:logger:Inserted 11511 rows into the database table sharing_service_chart_data.\n",
      "2024-01-04 20:22:30,178:logger:Log success\n",
      "2024-01-04 20:22:30,415:logger:Inserted 10 rows into the database table sharing_service_table_data.\n",
      "2024-01-04 20:22:30,444:logger:Log success\n",
      "2024-01-04 20:22:30,617:logger:Inserted 2558 rows into the database table content_type_chart_data.\n",
      "2024-01-04 20:22:30,632:logger:Log success\n",
      "2024-01-04 20:22:30,735:logger:Inserted 3 rows into the database table content_type_table_data.\n",
      "2024-01-04 20:22:30,753:logger:Log success\n",
      "2024-01-04 20:22:31,144:logger:Inserted 15348 rows into the database table totals_table_data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the root directory\n",
    "root_directory = './../Data/youtube-data/'\n",
    "\n",
    "sql_queries = \"\"\n",
    "\n",
    "\n",
    "totals_table_created = False  # Flag to track if Totals table has been created\n",
    "all_totals_data = pd.DataFrame()  # DataFrame to combine all Totals data\n",
    "\n",
    "# Iterate through each folder in the root directory\n",
    "for folder_name in os.listdir(root_directory):\n",
    "    folder_path = os.path.join(root_directory, folder_name)\n",
    "\n",
    "    # Check if the item is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        chart_data_path = os.path.join(folder_path, 'Chart data.csv')\n",
    "        table_data_path = os.path.join(folder_path, 'Table data.csv')\n",
    "        totals_data_path = os.path.join(folder_path, 'Totals.csv')\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # # Check if \"Chart data.csv\" or \"Table data.csv\" exists in the folder\n",
    "        if os.path.exists(chart_data_path):\n",
    "            chart_data_df = pd.read_csv(chart_data_path)\n",
    "            table_name = f'{folder_name.lower().replace(\" \",\"_\")}_chart_data'\n",
    "            table_query = create_table_query(chart_data_df, table_name)\n",
    "            sql_queries += table_query\n",
    "            # Process chart data\n",
    "   \n",
    "            run_sql_query(table_query)  # Create table if not exists\n",
    "            populate_dataframe_to_database(chart_data_df, table_name)\n",
    "\n",
    "        if os.path.exists(table_data_path):\n",
    "            # Process table data\n",
    "            table_data_df = pd.read_csv(table_data_path)\n",
    "            table_name = f'{folder_name.lower().replace(\" \",\"_\")}_table_data'\n",
    "\n",
    "            table_query = create_table_query(table_data_df, table_name)\n",
    "            sql_queries += table_query\n",
    "\n",
    "\n",
    "            run_sql_query(table_query)  # Create table if not exists\n",
    "            populate_dataframe_to_database(table_data_df, table_name)\n",
    "        \n",
    "        # Check if \"Totals.csv\" exists in the folder\n",
    "        if os.path.exists(totals_data_path):\n",
    "            totals_df = pd.read_csv(totals_data_path)\n",
    "            all_totals_data = pd.concat([all_totals_data, totals_df], ignore_index=True)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "# Create the CREATE TABLE query for totals_table_data\n",
    "totals_table_query = create_table_query(all_totals_data, 'totals_table_data')\n",
    "sql_queries += totals_table_query\n",
    "# Create the totals_table_data table\n",
    "\n",
    "# Specify the file path for the SQL file\n",
    "sql_file_path = './sql_queries.sql'\n",
    "\n",
    "# Write the SQL queries to the file\n",
    "with open(sql_file_path, 'w') as sql_file:\n",
    "    sql_file.write(sql_queries)\n",
    "\n",
    "\n",
    "run_sql_query(totals_table_query)\n",
    "\n",
    "# Insert the combined Totals data into totals_table_data\n",
    "populate_dataframe_to_database(all_totals_data, 'totals_table_data')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenx_week3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
